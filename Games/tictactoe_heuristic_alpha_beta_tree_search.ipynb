{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search: Solving Tic-Tac-Toe with Heuristic Alpha-Beta Tree Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "Multiplayer games can be implemented as:\n",
    "1. Nondeterministic actions: The opponent is seen as part of an environment with nondeterministic actions. Non-determinism is the result of the unknown opponent's moves. \n",
    "2. Optimal Decisions: Minimax search (search complete game tree) and alpha-beta pruning.\n",
    "3. __Heuristic Alpha-Beta Tree Search:__ Cut off tree search and use heuristic to estimate state value. \n",
    "4. Monte Carlo Tree search: Simulate playouts to estimate state value. \n",
    "\n",
    "Here we will implement search for Tic-Tac-Toe (see [rules](https://en.wikipedia.org/wiki/Tic-tac-toe)). The game is a __zero-sum game__: Win by x results in +1, win by o in -1 and a tie has a value of 0. Max plays x and tries to maximize the outcome while Min plays o and tries to minimize the outcome.   \n",
    "\n",
    "We will implement\n",
    "* Heuristic Alpha-Beta Tree Search\n",
    "\n",
    "The algorithms search the game tree and we could return a conditional plan (or partial plan if cut offs are used), but the implementation here only identifies and returns the optimal next move."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The board and helper functions\n",
    "\n",
    "I represent the board as a vector of length 9. The values are `' ', 'x', 'o'`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def empty_board():\n",
    "    return [' '] * 9\n",
    "\n",
    "board = empty_board()\n",
    "display(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ' ' ' ' ']\n",
      " [' ' ' ' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "\n",
      "Add some x's\n",
      "[['x' ' ' ' ']\n",
      " ['x' ' ' ' ']\n",
      " ['x' ' ' ' ']]\n"
     ]
    }
   ],
   "source": [
    "def show_board(board):\n",
    "    \"\"\"display the board\"\"\"\n",
    "    b = np.array(board).reshape((3,3))\n",
    "    print(b)\n",
    "\n",
    "board = empty_board()\n",
    "show_board(board)    \n",
    "\n",
    "print()\n",
    "print(\"Add some x's\")\n",
    "board[0] = 'x'; board[3] = 'x'; board[6] = 'x';  \n",
    "show_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['x' ' ' ' ']\n",
      " ['x' ' ' ' ']\n",
      " ['x' ' ' ' ']]\n",
      "Win? x\n",
      "\n",
      "[[' ' ' ' ' ']\n",
      " [' ' ' ' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "Win? n\n"
     ]
    }
   ],
   "source": [
    "def check_win(board):\n",
    "    \"\"\"check the board and return one of x, o, d (draw), or n (for next move)\"\"\"\n",
    "    \n",
    "    board = np.array(board).reshape((3,3))\n",
    "    \n",
    "    diagonals = np.array([[board[i][i] for i in range(len(board))], \n",
    "                          [board[i][len(board)-i-1] for i in range(len(board))]])\n",
    "    \n",
    "    for a_board in [board, np.transpose(board), diagonals]:\n",
    "        for row in a_board:\n",
    "            if len(set(row)) == 1 and row[0] != ' ':\n",
    "                return row[0]\n",
    "    \n",
    "    # check for draw\n",
    "    if(np.sum(board == ' ') < 1):\n",
    "        return 'd'\n",
    "    \n",
    "    return 'n'\n",
    "\n",
    "show_board(board)\n",
    "print('Win? ' + check_win(board))\n",
    "\n",
    "print()\n",
    "show_board(empty_board())\n",
    "print('Win? ' + check_win(empty_board()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['x' ' ' ' ']\n",
      " ['x' ' ' ' ']\n",
      " ['x' ' ' ' ']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 5, 7, 8]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_actions(board):\n",
    "    \"\"\"return possible actions as a vector ot indices\"\"\"\n",
    "    return np.where(np.array(board) == ' ')[0].tolist()\n",
    "\n",
    "    # randomize the action order\n",
    "    #actions = np.where(np.array(board) == ' ')[0]\n",
    "    #np.random.shuffle(actions)\n",
    "    #return actions.tolist()\n",
    "\n",
    "\n",
    "show_board(board)\n",
    "get_actions(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other(player): \n",
    "    if player == 'x': return 'o'\n",
    "    else: return 'x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ' ' ' ' ']\n",
      " [' ' ' ' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "\n",
      "State for placing an x at position 4:\n",
      "[[' ' ' ' ' ']\n",
      " [' ' 'x' ' ']\n",
      " [' ' ' ' ' ']]\n"
     ]
    }
   ],
   "source": [
    "def result(state, player, action):\n",
    "    \"\"\"Add move to the board.\"\"\"\n",
    "    \n",
    "    state = state.copy()\n",
    "    state[action] = player\n",
    "  \n",
    "    return state\n",
    "\n",
    "show_board(empty_board())\n",
    "\n",
    "print()\n",
    "print(\"State for placing an x at position 4:\")\n",
    "show_board(result(empty_board(), 'x', 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return utility for a state. Terminal states return the utility for Max as `+1`, -`1` or `0`. Non-terminal state have no utility and return `None`. Note that I use `utility is not None` to identify terminal states. That is, I use for `is_terminal(s)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "-1\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def utility(state, player = 'x'):\n",
    "    \"\"\"check is a state is terminal and return the utility if it is. None means not a terminal mode.\"\"\"\n",
    "    goal = check_win(state)        \n",
    "    if goal == player: return +1 \n",
    "    if goal == 'd': return 0  \n",
    "    if goal == other(player): return -1  # loss is failure\n",
    "    return None # continue\n",
    "\n",
    "print(utility(['x'] * 9))\n",
    "print(utility(['o'] * 9))\n",
    "print(utility(empty_board()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristic Alpha-Beta Tree Search\n",
    "\n",
    "See AIMA page 156ff. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fun(state, player = 'x'):\n",
    "    \"\"\"heuristic for utility of state. Returns score and if it is a terminal state.\n",
    "    1. For terminal states it is the utility. \n",
    "    2. For non-terminal states, it calculates a weighted linear function using features of the state. \n",
    "    The features we look at are 2 in a row/col/diagonal where the 3rd square is empty. We assume that\n",
    "    the more of these positions we have, the higher the chance of winning.\n",
    "    We need to be careful that the utility of the heuristic stays between [-1,1]. \n",
    "    Note that the largest possible number of these positions is 4. I weigh the count by 0.1, \n",
    "    guaranteeing that is in the needed range.\n",
    "    \n",
    "    Function Returns: heuistic value, terminal?\"\"\"\n",
    "    \n",
    "    # terminal state?\n",
    "    u = utility(state, player)\n",
    "    if u is not None: return u, True\n",
    "    \n",
    "    \n",
    "    score = 0\n",
    "    board = np.array(state).reshape((3,3))\n",
    "    diagonals = np.array([[board[i][i] for i in range(len(board))], \n",
    "                          [board[i][len(board)-i-1] for i in range(len(board))]])\n",
    "    \n",
    "    for a_board in [board, np.transpose(board), diagonals]:\n",
    "        for row in a_board:\n",
    "            if sum(row == player) == 2 and any(row ==' '): score += .1\n",
    "            if sum(row == other(player)) == 2 and any(row ==' '): score -= .1\n",
    "    \n",
    "    return score, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ' ' ' ' ']\n",
      " [' ' ' ' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "eval for x: (0, False)\n",
      "eval for o: (0, False)\n",
      "[['x' 'x' 'x']\n",
      " [' ' ' ' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "eval for x: (1, True)\n",
      "eval for o: (-1, True)\n",
      "[['x' 'x' ' ']\n",
      " ['x' 'o' ' ']\n",
      " [' ' ' ' 'o']]\n",
      "eval for x: (0.2, False)\n",
      "eval for o: (-0.2, False)\n",
      "[['x' 'o' ' ']\n",
      " ['x' 'o' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "eval for x: (0.0, False)\n",
      "eval for o: (0.0, False)\n"
     ]
    }
   ],
   "source": [
    "board = empty_board() \n",
    "show_board(board)\n",
    "print(f\"eval for x: {eval_fun(board)}\")\n",
    "print(f\"eval for o: {eval_fun(board, 'o')}\")\n",
    "\n",
    "board = empty_board() \n",
    "board[0] = 'x'\n",
    "board[1] = 'x'\n",
    "board[2] = 'x' \n",
    "show_board(board)\n",
    "print(f\"eval for x: {eval_fun(board)}\")\n",
    "print(f\"eval for o: {eval_fun(board, 'o')}\")\n",
    "\n",
    "board = empty_board() \n",
    "board[0] = 'x'\n",
    "board[1] = 'x'\n",
    "board[3] = 'x' \n",
    "board[4] = 'o'\n",
    "board[8] = 'o'\n",
    "show_board(board)\n",
    "print(f\"eval for x: {eval_fun(board)}\")\n",
    "print(f\"eval for o: {eval_fun(board, 'o')}\")\n",
    "\n",
    "board = empty_board() \n",
    "board[0] = 'x'\n",
    "board[1] = 'o'\n",
    "board[3] = 'x' \n",
    "board[4] = 'o'\n",
    "show_board(board)\n",
    "print(f\"eval for x: {eval_fun(board)}\")\n",
    "print(f\"eval for o: {eval_fun(board, 'o')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search with Cutoff\n",
    "\n",
    "We add a cutoff to the Recursive DFS algorithm for Minimax Search with Alpha-Beta Pruning (see AIMA page 156ff). We use the heuristic evaluation function and the back-up the value using minimax search with alpha-beta pruning to determine the next move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-14-3833d1415a8b>, line 48)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-3833d1415a8b>\"\u001b[0;36m, line \u001b[0;32m48\u001b[0m\n\u001b[0;31m    if(terminal):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# global variables\n",
    "DEBUG = 1 # 1 ... count nodes, 2 ... debug each node\n",
    "COUNT = 0\n",
    "\n",
    "def alpha_beta_search(board, cutoff = None, player = 'x'):\n",
    "    \"\"\"start the search. cutoff = None is minimax search with alpha-beta pruning.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "\n",
    "    value, move = max_value_ab(board, player, -math.inf, +math.inf, 0, cutoff)\n",
    "    \n",
    "    if DEBUG >= 1: print(f\"Number of nodes searched (cutoff = {cutoff}): {COUNT}\") \n",
    "    \n",
    "    return {\"move\": move, \"value\": value}\n",
    "\n",
    "def max_value_ab(state, player, alpha, beta, depth, cutoff):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # cut off and terminal test\n",
    "    v, terminal = eval_fun(state, player)\n",
    "    if((cutoff is not None and depth >= cutoff) or terminal): \n",
    "        if(terminal): alpha, beta = v, v\n",
    "        if DEBUG >= 2: print(f\"stopped at {depth}: {state} term: {terminal} eval: {v} [{alpha}, {beta}]\" ) \n",
    "        return v, None\n",
    "    \n",
    "    v, move = -math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in get_actions(state):\n",
    "        v2, a2 = min_value_ab(result(state, player, a), player, alpha, beta, depth + 1, cutoff)\n",
    "        if v2 > v:\n",
    "            v, move = v2, a\n",
    "            alpha = max(alpha, v)\n",
    "        if v >= beta: return v, move\n",
    "    \n",
    "    return v, move\n",
    "\n",
    "def min_value_ab(state, player, alpha, beta, depth, cutoff):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # cut off and terminal test\n",
    "    v, terminal = eval_fun(state, player)\n",
    "    if((cutoff is not None and depth >= cutoff) or terminal): \n",
    "    if(terminal): \n",
    "        if(terminal): alpha, beta = v, v\n",
    "        if DEBUG >= 2: print(f\"stopped at {depth}: {state} term: {terminal} eval: {v} [{alpha}, {beta}]\" ) \n",
    "        return v, None\n",
    "    \n",
    "    v, move = +math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update beta and return move with the smallest value\n",
    "    for a in get_actions(state):\n",
    "        v2, a2 = max_value_ab(result(state, other(player), a), player, alpha, beta, depth + 1, cutoff)\n",
    "        if v2 < v:\n",
    "            v, move = v2, a\n",
    "            beta = min(beta, v)\n",
    "        if v <= alpha: return v, move\n",
    "    \n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is about to win (play 8)\n",
    "\n",
    "board = empty_board() \n",
    "board[0] = 'x'\n",
    "board[1] = 'o'\n",
    "board[3] = 'o'\n",
    "board[4] = 'x'\n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "print()\n",
    "%time display(alpha_beta_search(board, 2))\n",
    "\n",
    "print()\n",
    "%time display(alpha_beta_search(board, 4))\n",
    "\n",
    "print()\n",
    "%time display(alpha_beta_search(board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o is about to win\n",
    "\n",
    "board = empty_board() \n",
    "board[0] = 'o'\n",
    "board[1] = 'o'\n",
    "board[3] = 'o'\n",
    "board[4] = 'x'\n",
    "board[8] = 'x'\n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "print()\n",
    "%time display(alpha_beta_search(board, 2))\n",
    "print()\n",
    "%time display(alpha_beta_search(board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### x can draw if it chooses 7.\n",
    "\n",
    "board = empty_board() \n",
    "board[0] = 'x'\n",
    "board[1] = 'o'\n",
    "board[2] = 'x'\n",
    "board[4] = 'o'\n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "print()\n",
    "%time display(alpha_beta_search(board, 2))\n",
    "print()\n",
    "%time display(alpha_beta_search(board, 4))\n",
    "print()\n",
    "%time display(alpha_beta_search(board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o went first\n",
    "\n",
    "board = empty_board() \n",
    "board[4] = 'o'\n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "print()\n",
    "%time display(alpha_beta_search(board, 2))\n",
    "print()\n",
    "%time display(alpha_beta_search(board, 4))\n",
    "print()\n",
    "%time display(alpha_beta_search(board))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note:_ The heuristic thinks at cutoffs of 2 and 4 that is will most likely lose!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Empty board: Only a draw an be guaranteed\n",
    "\n",
    "board = empty_board() \n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "\n",
    "print()\n",
    "%time display(alpha_beta_search(board, 2))\n",
    "print()\n",
    "%time display(alpha_beta_search(board, 4))\n",
    "print()\n",
    "%time display(alpha_beta_search(board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A bad situation\n",
    "\n",
    "board = empty_board() \n",
    "board[0] = 'o'\n",
    "board[2] = 'x'\n",
    "board[8] = 'o'\n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "print()\n",
    "%time display(alpha_beta_search(board, 2))\n",
    "print()\n",
    "%time display(alpha_beta_search(board, 4))\n",
    "print()\n",
    "%time display(alpha_beta_search(board))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "\n",
    "### Baseline: Randomized Player\n",
    "\n",
    "A completely randomized player agent should be a weak baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_player(board, player = None):\n",
    "    \"\"\"Simple player that chooses a random empy square. player is unused\"\"\"\n",
    "    return np.random.choice(get_actions(board))\n",
    "\n",
    "show_board(board)\n",
    "random_player(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Environment\n",
    "\n",
    "Implement the environment that calls the agent. The percept is the board and the action is move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = 0\n",
    "\n",
    "def switch_player(player, x, o):\n",
    "    if player == 'x':\n",
    "        return 'o', o\n",
    "    else:\n",
    "        return 'x', x\n",
    "\n",
    "def play(x, o, N = 100):\n",
    "    results = {'x': 0, 'o': 0, 'd': 0}\n",
    "    for i in range(N):\n",
    "        board = empty_board()\n",
    "        player, fun = 'x', x\n",
    "        \n",
    "        while True:\n",
    "            a = fun(board, player)\n",
    "            board = result(board, player, a)\n",
    "            \n",
    "            win = check_win(board)\n",
    "            if win != 'n':\n",
    "                if DEBUG >= 1: print(f\"{board} winner: {win}\")\n",
    "                results[win] += 1\n",
    "                break\n",
    "            \n",
    "            player, fun = switch_player(player, x, o)   \n",
    " \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random vs. Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time display(play(random_player, random_player))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimax with Alpha-Beta Pruning vs. Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def heuristic2_player(board, player = 'x'):\n",
    "    return alpha_beta_search(board, cutoff = 2, player = player)[\"move\"]\n",
    "\n",
    "def heuristic4_player(board, player = 'x'):\n",
    "    return alpha_beta_search(board, cutoff = 4, player = player)[\"move\"]\n",
    "\n",
    "def alpha_beta_player(board, player = 'x'):\n",
    "    return alpha_beta_search(board, cutoff = None, player = player)[\"move\"]\n",
    "\n",
    "DEBUG = 1\n",
    "print(\"heuristic2 vs. random:\")\n",
    "display(play(heuristic2_player, random_player, N = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = 0\n",
    "print(\"heuristic2 vs. random:\")\n",
    "%time display(play(heuristic2_player, random_player))\n",
    "\n",
    "print(\"heuristic4 vs. random:\")\n",
    "%time display(play(heuristic4_player, random_player))\n",
    "\n",
    "print()\n",
    "print(\"random vs. heuristic2\")\n",
    "%time display(play(random_player, heuristic2_player))\n",
    "\n",
    "print(\"random vs. heuristic4\")\n",
    "%time display(play(random_player, heuristic4_player))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic vs. Minimax with Alpha-Beta Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = 0\n",
    "\n",
    "# Note: No randomness -> play only once\n",
    "\n",
    "print(\"heuristic2 vs. alpha_beta\")\n",
    "%time display(play(heuristic2_player, alpha_beta_player, N = 1))\n",
    "\n",
    "print()\n",
    "print(\"alpha_beta vs. heuristic2\")\n",
    "%time display(play(alpha_beta_player, heuristic2_player, N = 1))\n",
    "\n",
    "print()\n",
    "print(\"heuristic4 vs alpha_beta\")\n",
    "%time display(play(heuristic4_player, alpha_beta_player, N = 1))\n",
    "\n",
    "print()\n",
    "print(\"alpha_beta vs. heuristic4\")\n",
    "%time display(play(alpha_beta_player, heuristic4_player, N = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic vs. Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DEBUG = 0\n",
    "\n",
    "# Note: No randomness -> play only once\n",
    "\n",
    "print(\"heuristic2 vs. heuristic4\")\n",
    "%time display(play(heuristic2_player, heuristic4_player, N = 1))\n",
    "\n",
    "print()\n",
    "print(\"heuristic4 vs. heuristic2\")\n",
    "%time display(play(heuristic6_player, heuristic2_player, N = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Idea:__ Start experiments with different boards that already have a few x's and o's randomly placed on them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
