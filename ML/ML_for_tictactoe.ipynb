{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn to Score a Tic-Tac-Toe Board by Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "\n",
    "We want to use machine learning to support intelligent agents playing Tic-Tac-Toe (see [rules](https://en.wikipedia.org/wiki/Tic-tac-toe)). Here is the approach:\n",
    "\n",
    "1. Simulate playouts to create labeled training data. The data $X$ is the board and the label $y$ indicates if the game resulted in a win or a loss.\n",
    "2. Learn a model to predict the probability that we will win a given board. More specifically, we will learn here a function that predicts a score normalzed to a probability of a win for each board (i.e., $\\hat{P}(y = \\mathrm{win} | x) = h(x)$).\n",
    "3. The model can be applied as:\n",
    "   - the heuristic evaluation function for Heuristic Minimax Search.\n",
    "   - a playout policy for better simulated games used in Pure Monte Carlo Search/Monte Carlo Tree Search.\n",
    "   - self-play where we learn a model, use the model as the playout policy to create more a realistic training data for a better model. We keep on doing that as long as the model improves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The board\n",
    "\n",
    "I represent the board as a vector of length 9. The values are `' ', 'x', 'o'`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.3f'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "%precision 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def empty_board():\n",
    "    return [' '] * 9\n",
    "\n",
    "board = empty_board()\n",
    "display(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ' ' ' ' ']\n",
      " [' ' ' ' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "\n",
      "Add some x's\n",
      "[['x' ' ' ' ']\n",
      " ['x' ' ' ' ']\n",
      " ['x' ' ' ' ']]\n"
     ]
    }
   ],
   "source": [
    "def show_board(board):\n",
    "    \"\"\"display the board\"\"\"\n",
    "    b = np.array(board).reshape((3,3))\n",
    "    print(b)\n",
    "\n",
    "board = empty_board()\n",
    "show_board(board)    \n",
    "\n",
    "print()\n",
    "print(\"Add some x's\")\n",
    "board[0] = 'x'; board[3] = 'x'; board[6] = 'x';  \n",
    "show_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['x' ' ' ' ']\n",
      " ['x' ' ' ' ']\n",
      " ['x' ' ' ' ']]\n",
      "Win? x\n",
      "\n",
      "[[' ' ' ' ' ']\n",
      " [' ' ' ' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "Win? n\n"
     ]
    }
   ],
   "source": [
    "def check_win(board):\n",
    "    \"\"\"check the board and return one of x, o, d (draw), or n (for next move)\"\"\"\n",
    "    \n",
    "    board = np.array(board).reshape((3,3))\n",
    "    \n",
    "    diagonals = np.array([[board[i][i] for i in range(len(board))], \n",
    "                          [board[i][len(board)-i-1] for i in range(len(board))]])\n",
    "    \n",
    "    for a_board in [board, np.transpose(board), diagonals]:\n",
    "        for row in a_board:\n",
    "            if len(set(row)) == 1 and row[0] != ' ':\n",
    "                return row[0]\n",
    "    \n",
    "    # check for draw\n",
    "    if(np.sum(board == ' ') < 1):\n",
    "        return 'd'\n",
    "    \n",
    "    return 'n'\n",
    "\n",
    "show_board(board)\n",
    "print('Win? ' + check_win(board))\n",
    "\n",
    "print()\n",
    "show_board(empty_board())\n",
    "print('Win? ' + check_win(empty_board()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ' ' ' ' ']\n",
      " [' ' ' ' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "\n",
      "State for placing an x at position 4:\n",
      "[[' ' ' ' ' ']\n",
      " [' ' 'x' ' ']\n",
      " [' ' ' ' ' ']]\n"
     ]
    }
   ],
   "source": [
    "def result(state, player, action):\n",
    "    \"\"\"Add move to the board.\"\"\"\n",
    "    \n",
    "    state = state.copy()\n",
    "    state[action] = player\n",
    "  \n",
    "    return state\n",
    "\n",
    "show_board(empty_board())\n",
    "\n",
    "print()\n",
    "print(\"State for placing an x at position 4:\")\n",
    "show_board(result(empty_board(), 'x', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other(player): \n",
    "    if player == 'x': return 'o'\n",
    "    else: return 'x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "-1\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def utility(state, player = 'x'):\n",
    "    \"\"\"check is a state is terminal and return the utility if it is. None means not a terminal mode.\"\"\"\n",
    "    goal = check_win(state)        \n",
    "    if goal == player: return +1 \n",
    "    if goal == 'd': return 0  \n",
    "    if goal == other(player): return -1  # loss is failure\n",
    "    return None # continue\n",
    "\n",
    "print(utility(['x'] * 9))\n",
    "print(utility(['o'] * 9))\n",
    "print(utility(empty_board()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['x' ' ' ' ']\n",
      " ['x' ' ' ' ']\n",
      " ['x' ' ' ' ']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 5, 7, 8]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_actions(board):\n",
    "    \"\"\"return possible actions as a vector ot indices\"\"\"\n",
    "    return np.where(np.array(board) == ' ')[0].tolist()\n",
    "\n",
    "    # randomize the action order\n",
    "    #actions = np.where(np.array(board) == ' ')[0]\n",
    "    #np.random.shuffle(actions)\n",
    "    #return actions.tolist()\n",
    "    \n",
    "show_board(board)\n",
    "get_actions(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Data using Playouts\n",
    "\n",
    "We will try to learn a function $\\hat{y} = h(x)$ where $x$ is a board and $y$ is the estimated utility. The data we need to learn this model can be creating by running playouts (complete games) and recording the boards and mark them as leading to a win, loss or draw. Note: I learn a model that is specific to a player by using only the boards resulting from a move of that player.  \n",
    "\n",
    "To describe $x$ for the learning algorithm, I translate empty cells to 0, `x` to 1 and `o` to -1. For $y$ I use the utility defined for win (1), loss (-1), and tie (0).\n",
    "\n",
    "We will start with a **randomized playout policy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def playout_policy_random(state, player = 'x'):\n",
    "    return np.random.choice(get_actions(state))\n",
    "    \n",
    "playout_policy = playout_policy_random\n",
    "playout_policy(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  [0, 0, -1, 0, 0, 0, 1, 0, 1],\n",
       "  [0, -1, -1, 0, 0, 0, 1, 1, 1]],\n",
       " [1, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = {' ': 0, 'x': 1, 'o': -1} # I translate the board into numbers\n",
    "\n",
    "def encode_state(state):\n",
    "    \"\"\"Represent the board as a vector of numbers.\"\"\"\n",
    "    return [tr[s] for s in state]\n",
    "\n",
    "def playout_record(player = 'x'):\n",
    "    \"\"\"Run a playout and record the boards after the player's move.\"\"\"\n",
    "    state = empty_board()\n",
    "    current_player = 'x'\n",
    "    \n",
    "    boards = []\n",
    "    \n",
    "    while(True):\n",
    "        # reached terminal state?\n",
    "        u = utility(state, player)\n",
    "        if u is not None: return(boards, [u] * len(boards))\n",
    "  \n",
    "        a = playout_policy(state, current_player)\n",
    "        state = result(state, current_player, a)   \n",
    "  \n",
    "        if current_player == player:\n",
    "            boards.append(encode_state(state))\n",
    "\n",
    "        # switch between players\n",
    "        current_player = other(current_player)\n",
    "\n",
    "playout_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `N` playouts and create a pandas dataframe for `X` and a numpy array for `y`. These data structures work for `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8336</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8337</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8338</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8339</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8340</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8341 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8\n",
       "0     0  0  0  1  0  0  0  0  0\n",
       "1     0  0  0  1  0  0  1 -1  0\n",
       "2     0  0  0  1  0 -1  1 -1  1\n",
       "3    -1  0  1  1  0 -1  1 -1  1\n",
       "4    -1  1  1  1 -1 -1  1 -1  1\n",
       "...  .. .. .. .. .. .. .. .. ..\n",
       "8336 -1  1  1  1 -1 -1 -1  1  1\n",
       "8337  0  0  0  0  0  0  0  1  0\n",
       "8338 -1  1  0  0  0  0  0  1  0\n",
       "8339 -1  1  0  0 -1  1  0  1  0\n",
       "8340 -1  1 -1  0 -1  1  0  1  1\n",
       "\n",
       "[8341 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., -1, -1, -1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_data(N = 100, record = 'x'):\n",
    "    board = []\n",
    "    utility = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        b, u = playout_record(record)\n",
    "        board.extend(b)\n",
    "        utility.extend(u)\n",
    "        \n",
    "    return {'X': pd.DataFrame(board), 'y': np.array(utility)}\n",
    "\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "data = create_data(2000)\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "print(\"X:\")\n",
    "display(X)\n",
    "\n",
    "print(\"y:\")\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data in training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learn an Artificial Neural Network (ANN) to approximate $y = f(X)$ by $\\hat{y} = h(X)$. See\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "\n",
    "ANNs are popular for this kind of task but other classification models can also be used (e.g., decision trees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.48 s, sys: 0 ns, total: 9.48 s\n",
      "Wall time: 9.49 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=100, max_iter=1000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "                    hidden_layer_sizes = (100),\n",
    "                    max_iter = 1000\n",
    "                    ) \n",
    "                    \n",
    "%time mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model size (number of weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: (9, 100)\n",
      "Layer 2: (100, 3)\n",
      "Total number of weights: 1200\n"
     ]
    }
   ],
   "source": [
    "print(\"Layer 1:\", np.shape(mlp.coefs_[0]))\n",
    "print(\"Layer 2:\", np.shape(mlp.coefs_[1]))\n",
    "\n",
    "print(\"Total number of weights:\", np.product(np.shape(mlp.coefs_[0])) + np.product(np.shape(mlp.coefs_[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model against the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test:\t [-1, 1, -1, 1, -1, 1, 0, 1, 0, 1]\n",
      "pred:\t [ 1  1  1  1  1 -1  0  1  0  1]\n",
      "Confusion matrix:\n",
      " [[179  34 114]\n",
      " [ 16 101  44]\n",
      " [235 132 814]]\n",
      "Accuracy: 0.6554823247453565\n"
     ]
    }
   ],
   "source": [
    "pred = mlp.predict(X_test)\n",
    "\n",
    "print(\"y_test:\\t\", list(y_test)[0:10])\n",
    "print(\"pred:\\t\",   pred[0:10])\n",
    "\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(pred, y_test))\n",
    "print(\"Accuracy:\", accuracy_score(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ The accuracy is not great since we have many boards with only a few moves on it. Since these boards can easily lead to wins, losses or ties, they produce many errors.\n",
    "\n",
    "Here is the number of empty cells for each board in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7352    2\n",
       "7422    4\n",
       "7235    6\n",
       "5534    2\n",
       "5585    8\n",
       "       ..\n",
       "2732    8\n",
       "1101    4\n",
       "5698    2\n",
       "383     4\n",
       "4451    6\n",
       "Length: 1669, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_test == 0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test only on boards that have only three or less cells left to play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "take = list((X_test == 0).sum(axis=1)<=3)\n",
    "\n",
    "X_test2 = X_test[take]\n",
    "y_test2 = y_test[take]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.836864406779661\n"
     ]
    }
   ],
   "source": [
    "pred2 = mlp.predict(X_test2)\n",
    "print(f\"Accuracy:\", accuracy_score(pred2, y_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__More Notes:__ \n",
    "\n",
    "* The board is symmetric. You could use deep learning with convolution layers to create better models.\n",
    "* The tic-tac-toe board is small and we used 2000 playouts. This covers a large space of the search space. If you have a more complicated game, \n",
    "    then you would need to do self-play to learn better and better playout policies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Tests\n",
    "\n",
    "We evaluate some boards where `x` just made a move. The classifier tries to predict the most likely outcome\n",
    "of the game as -1 = `o` wins, 0 = draw, and 1 = `x` wins. The classifier can also predict the probability of the three possible outcomes. We can use these probabilities as weights to calculate the expected utility in the range $[-1,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval_board(board):\n",
    "    print(\"Board:\")\n",
    "    show_board(board)\n",
    "\n",
    "    pred = mlp.predict(pd.DataFrame([encode_state(board)]))\n",
    "    print(\"\\nPredicted game outcome:\", pred)\n",
    "\n",
    "    probs = mlp.predict_proba(pd.DataFrame([encode_state(board)]))\n",
    "    print(\"Predicted probability [loss, draw, win]:\", probs)\n",
    "    print(\"Expected utility:\", np.sum(probs * [-1,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n",
      "[['x' 'x' ' ']\n",
      " ['o' 'x' ' ']\n",
      " ['o' ' ' ' ']]\n",
      "\n",
      "Predicted game outcome: [1]\n",
      "Predicted probability [loss, draw, win]: [[8.641e-02 8.183e-04 9.128e-01]]\n",
      "Expected utility: 0.8263553792688264\n"
     ]
    }
   ],
   "source": [
    "# x will win\n",
    "\n",
    "board = ['x', 'x', ' ',\n",
    "         'o', 'x', ' ',\n",
    "         'o', ' ', ' ']\n",
    "\n",
    "print_eval_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n",
      "[['o' 'x' ' ']\n",
      " ['x' 'o' 'x']\n",
      " ['o' ' ' ' ']]\n",
      "\n",
      "Predicted game outcome: [-1]\n",
      "Predicted probability [loss, draw, win]: [[0.953 0.011 0.036]]\n",
      "Expected utility: -0.9174997985317431\n"
     ]
    }
   ],
   "source": [
    "# x made a mistake and will lose.\n",
    "\n",
    "board = ['o', 'x', ' ',\n",
    "         'x', 'o', 'x',\n",
    "         'o', ' ', ' ']\n",
    "    \n",
    "print_eval_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n",
      "[['x' 'o' 'x']\n",
      " [' ' 'o' ' ']\n",
      " [' ' 'x' ' ']]\n",
      "\n",
      "Predicted game outcome: [0]\n",
      "Predicted probability [loss, draw, win]: [[0.1   0.631 0.269]]\n",
      "Expected utility: 0.16903114678744696\n"
     ]
    }
   ],
   "source": [
    "# This will be a draw\n",
    "\n",
    "board = ['x', 'o', 'x',\n",
    "         ' ', 'o', ' ',\n",
    "         ' ', 'x', ' ']\n",
    "\n",
    "print_eval_board(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Predictions to find the Best Move\n",
    "\n",
    "The predict function can be used for\n",
    "   - the heuristic evaluation function for Heuristic Minimax Search.\n",
    "   - a better playout policy for simulated games used in Pure Monte Carlo Search/Monte Carlo Tree Search. If we use it as a playout strategy to create data for learning better ML models, then this is called _self-play_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I show here how to use the model as a heuristic evaluation function for all boards that the player `x` can get to with its next move. The player then chooses the move with the highest heuristic value (printed as \"best action\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Empty board: Place in the center (or at least a corner).\n",
      "[[' ' ' ' ' ']\n",
      " [' ' ' ' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "x chooses 0; expected utility = +0.33\n",
      "x chooses 1; expected utility = +0.19\n",
      "x chooses 2; expected utility = +0.28\n",
      "x chooses 3; expected utility = +0.20\n",
      "x chooses 4; expected utility = +0.51\n",
      "x chooses 5; expected utility = +0.22\n",
      "x chooses 6; expected utility = +0.35\n",
      "x chooses 7; expected utility = -0.01\n",
      "x chooses 8; expected utility = +0.39\n",
      "Best action: 4\n",
      "\n",
      "# Play 7 to avoid loss.\n",
      "[['x' 'o' 'x']\n",
      " [' ' 'o' ' ']\n",
      " [' ' ' ' ' ']]\n",
      "x chooses 3; expected utility = -0.11\n",
      "x chooses 5; expected utility = -0.40\n",
      "x chooses 6; expected utility = -0.22\n",
      "x chooses 7; expected utility = +0.17\n",
      "x chooses 8; expected utility = -0.25\n",
      "Best action: 7\n",
      "\n",
      "# Play 4 to win.\n",
      "[['o' 'x' ' ']\n",
      " [' ' ' ' 'x']\n",
      " [' ' ' ' 'o']]\n",
      "x chooses 2; expected utility = -0.93\n",
      "x chooses 3; expected utility = -0.44\n",
      "x chooses 4; expected utility = +0.31\n",
      "x chooses 6; expected utility = +0.65\n",
      "x chooses 7; expected utility = -0.23\n",
      "Best action: 6\n"
     ]
    }
   ],
   "source": [
    "def eval_fun_ML(state, player = 'x'):\n",
    "    p = mlp.predict_proba(pd.DataFrame([encode_state(state)]))\n",
    "    val = np.sum(p * [-1, 0 , 1])\n",
    "    return val\n",
    "    \n",
    "\n",
    "def best_move(state, player = 'x', verbose = False):  \n",
    "    action = None\n",
    "    value = -math.inf\n",
    "\n",
    "    for a in get_actions(state) : \n",
    "        b = result(state.copy(), player, a)\n",
    "        val = eval_fun_ML(b, player)\n",
    "        if (verbose):\n",
    "            print(\"%s chooses %d; expected utility = %+1.2f\" % (player, a, val))\n",
    "\n",
    "        if val > value:\n",
    "            value = val\n",
    "            action = a\n",
    "        \n",
    "    return action\n",
    "  \n",
    "    \n",
    "print(\"# Empty board: Place in the center (or at least a corner).\")\n",
    "board = empty_board()\n",
    "show_board(board)\n",
    "print(\"Best action:\", best_move(board, verbose = True))\n",
    "\n",
    "print(\"\\n# Play 7 to avoid loss.\")\n",
    "board = ['x', 'o', 'x',\n",
    "         ' ', 'o', ' ',\n",
    "         ' ', ' ', ' ']\n",
    "show_board(board)\n",
    "print(\"Best action:\", best_move(board, verbose = True))\n",
    "\n",
    "print(\"\\n# Play 4 to win.\")\n",
    "board = ['o', 'x', ' ',\n",
    "         ' ', ' ', 'x',\n",
    "         ' ', ' ', 'o']\n",
    "show_board(board)\n",
    "print(\"Best action:\", best_move(board, verbose = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on Self-Play\n",
    "\n",
    "You need to learn a model for each player and use it in the playout strategy to create better data. Then learn new models and repeat."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
